{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "aa3 = \"ALA CYS ASP GLU PHE GLY HIS ILE LYS LEU MET ASN PRO GLN ARG SER THR VAL TRP TYR\".split()\n",
    "\n",
    "df = pd.read_pickle('protdiag_15.pkl')\n",
    "df.amino_acid = df.amino_acid.astype('category')\n",
    "df.amino_acid.cat.set_categories(aa3)\n",
    "df.site = df.site.astype('int')\n",
    "onehot = pd.get_dummies(df.amino_acid)\n",
    "df = df.join(onehot)\n",
    "end_time = time.time()\n",
    "\n",
    "ind = df.index.unique(level=0)\n",
    "\n",
    "validation_df = df.loc[ind[4000:4100]]\n",
    "df = pd.concat((df[df['site'] == 1].iloc[:1000],df[df['site'] == 0].iloc[:1000]))\n",
    "\n",
    "\n",
    "print(end_time - start_time, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['site']==1].size/ df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "pe = diagrams.PersistenceEntropy(\n",
    "    normalize=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pers_feat = pe.fit_transform(np.stack(df['persistence'].to_numpy()) )\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "df['entropy_0'] = pers_feat[:,0]\n",
    "df['entropy_1'] = pers_feat[:,1]\n",
    "df['entropy_2'] = pers_feat[:,2]\n",
    "del pers_feat\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "pe = diagrams.PersistenceEntropy(\n",
    "    normalize=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pers_feat = pe.fit_transform(np.stack(validation_df['persistence'].to_numpy()) )\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "validation_df['entropy_0'] = pers_feat[:,0]\n",
    "validation_df['entropy_1'] = pers_feat[:,1]\n",
    "validation_df['entropy_2'] = pers_feat[:,2]\n",
    "del pers_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "amp1 = diagrams.Amplitude(metric='wasserstein', n_jobs=-1)\n",
    "\n",
    "amp1_feat = amp1.fit_transform(np.stack(df['persistence'].to_numpy()))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "df['amp1_0'] = amp1_feat[:, 0]\n",
    "df['amp1_1'] = amp1_feat[:, 1]\n",
    "df['amp1_2'] = amp1_feat[:, 2]\n",
    "del amp1_feat\n",
    "\n",
    "start_time = time.time()\n",
    "amp1 = diagrams.Amplitude(metric='wasserstein', n_jobs=-1)\n",
    "\n",
    "amp1_feat = amp1.fit_transform(np.stack(validation_df['persistence'].to_numpy()))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "validation_df['amp1_0'] = amp1_feat[:, 0]\n",
    "validation_df['amp1_1'] = amp1_feat[:, 1]\n",
    "validation_df['amp1_2'] = amp1_feat[:, 2]\n",
    "del amp1_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "amp2 = diagrams.Amplitude(metric='bottleneck', n_jobs=-1)\n",
    "\n",
    "amp2_feat = amp2.fit_transform(np.stack(df['persistence'].to_numpy()))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "df['amp2_0'] = amp2_feat[:, 0]\n",
    "df['amp2_1'] = amp2_feat[:, 1]\n",
    "df['amp2_2'] = amp2_feat[:, 2]\n",
    "\n",
    "del amp2_feat\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "amp2 = diagrams.Amplitude(metric='bottleneck', n_jobs=-1)\n",
    "\n",
    "amp2_feat = amp2.fit_transform(np.stack(validation_df['persistence'].to_numpy()))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "validation_df['amp2_0'] = amp2_feat[:, 0]\n",
    "validation_df['amp2_1'] = amp2_feat[:, 1]\n",
    "validation_df['amp2_2'] = amp2_feat[:, 2]\n",
    "\n",
    "del amp2_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "amp3 = diagrams.Amplitude(metric='landscape', n_jobs=-1)\n",
    "\n",
    "\n",
    "amp3_feat = amp3.fit_transform(np.stack(df['persistence'].to_numpy()))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "df['amp3_0'] = amp3_feat[:, 0]\n",
    "df['amp3_1'] = amp3_feat[:, 1]\n",
    "df['amp3_2'] = amp3_feat[:, 2]\n",
    "\n",
    "del amp3_feat\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "amp3 = diagrams.Amplitude(metric='landscape', n_jobs=-1)\n",
    "\n",
    "\n",
    "amp3_feat = amp3.fit_transform(np.stack(validation_df['persistence'].to_numpy()))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "validation_df['amp3_0'] = amp3_feat[:, 0]\n",
    "validation_df['amp3_1'] = amp3_feat[:, 1]\n",
    "validation_df['amp3_2'] = amp3_feat[:, 2]\n",
    "\n",
    "del amp3_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "amp4 = diagrams.Amplitude(metric='betti', n_jobs=-1)\n",
    "\n",
    "amp4_feat = amp4.fit_transform(np.stack(df['persistence'].to_numpy()))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "df['amp4_0'] = amp4_feat[:, 0]\n",
    "df['amp4_1'] = amp4_feat[:, 1]\n",
    "df['amp4_2'] = amp4_feat[:, 2]\n",
    "\n",
    "del amp4\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "amp4 = diagrams.Amplitude(metric='betti', n_jobs=-1)\n",
    "\n",
    "amp4_feat = amp4.fit_transform(np.stack(validation_df['persistence'].to_numpy()))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "validation_df['amp4_0'] = amp4_feat[:, 0]\n",
    "validation_df['amp4_1'] = amp4_feat[:, 1]\n",
    "validation_df['amp4_2'] = amp4_feat[:, 2]\n",
    "\n",
    "del amp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pnts = diagrams.NumberOfPoints( n_jobs=-1)\n",
    "\n",
    "pnts_feat = pnts.fit_transform(np.stack(df['persistence'].to_numpy()))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "df['pnts_0'] = pnts_feat[:, 0]\n",
    "df['pnts_1'] = pnts_feat[:, 1]\n",
    "df['pnts_2'] = pnts_feat[:, 2]\n",
    "\n",
    "del pnts\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pnts = diagrams.NumberOfPoints( n_jobs=-1)\n",
    "\n",
    "pnts_feat = pnts.fit_transform(np.stack(validation_df['persistence'].to_numpy()))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 's')\n",
    "\n",
    "validation_df['pnts_0'] = pnts_feat[:, 0]\n",
    "validation_df['pnts_1'] = pnts_feat[:, 1]\n",
    "validation_df['pnts_2'] = pnts_feat[:, 2]\n",
    "\n",
    "del pnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['entropy_0', 'entropy_1', 'entropy_2',\n",
    "            'amp1_0','amp1_1', 'amp1_2',\n",
    "            'amp2_0','amp2_1', 'amp2_2',\n",
    "            'amp3_0','amp3_1', 'amp3_2',\n",
    "            'amp4_0','amp4_1', 'amp4_2',\n",
    "            'pnts_0', 'pnts_1', 'pnts_2'] + aa3\n",
    "\n",
    "\n",
    "X = df[features].values\n",
    "Y = df['site'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "#classifier = LinearSVC()\n",
    "classifier = SVC(max_iter=10000, probability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(classifier.predict(X_test) == Y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(classifier.predict_proba(X_test[Y_test==0])[:, 1], bins=20, alpha=0.5, label='not_binding')\n",
    "\n",
    "plt.hist(classifier.predict_proba(X_test[Y_test==1])[:,1], bins=20, alpha=0.5, label='binding_site')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df['old_prob'] = classifier.predict_proba(scaler.transform(validation_df[features].values))[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = validation_df[['site', 'old_prob']]\n",
    "results['pred'] = (results.loc[:,'old_prob'] > 0.5).apply(lambda x : int(x))\n",
    "\n",
    "precision = (results[results.pred == 1]['pred'] == results[results.pred == 1]['site']).mean()\n",
    "\n",
    "recall = (results[results.site == 1]['pred'] == results[results.site == 1]['site']).mean()\n",
    "\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newvalidation_df = pd.DataFrame()\n",
    "def smooth(res):\n",
    "\n",
    "    center = small_test.loc[res, ['x', 'y', 'z']].to_numpy()\n",
    "    small_test['weight'] = np.exp(-((small_test.loc[:,'x'] - center[0])**2 + (small_test.loc[:,'y'] - center[1])**2 + (small_test.loc[:, 'z'] - center[2])**2) / 20)\n",
    "    return (small_test['weight']*small_test['old_prob']).sum()/(small_test['weight'].to_numpy().sum())\n",
    "    \n",
    "\n",
    "for prot in tqdm(validation_df.index.unique(level=0)):\n",
    "    small_test= validation_df.loc[prot]    \n",
    "    small_test['new_prob'] = small_test.loc[:,'res_num'].apply(smooth)\n",
    "    newvalidation_df = newvalidation_df.append(small_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = newvalidation_df[['site', 'new_prob']]\n",
    "results['pred'] = (results.loc[:,'new_prob'] > 0.5).apply(lambda x : int(x))\n",
    "\n",
    "precision = (results[results.pred == 1]['pred'] == results[results.pred == 1]['site']).mean()\n",
    "\n",
    "recall = (results[results.site == 1]['pred'] == results[results.site == 1]['site']).mean()\n",
    "\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(validation_df[validation_df['site'] == 0]['old_prob'], bins=10, alpha=0.5, label='not_binding')\n",
    "\n",
    "plt.hist(validation_df[validation_df['site'] == 1]['old_prob'], bins=10, alpha=0.5, label='binding_site')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(newvalidation_df[newvalidation_df['site'] == 0]['new_prob'], bins=10, alpha=0.5, label='not_binding')\n",
    "\n",
    "plt.hist(newvalidation_df[newvalidation_df['site'] == 1]['new_prob'], bins=10, alpha=0.5, label='binding_site')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
